# Лабораторная работа 1

## Задание
1. Реализуйте градиентный спуск с постоянным шагом (learning rate). Исследовать сходимость при различных значениях шага.
2. Подберите функцию изменения шага (learning rate scheduling), чтобы улучшить
сходимость. Например экспоненциальную или ступенчатую.
3. Реализовать какой-нибудь метод одномерного поиска (дихотомия, метод Фибоначчи, метод золотого сечения) и градиентный спуск на его основе. Сравнить
эффективность с точки зрения количества вычислений минимизируемой функции и ее градиентов.
4. Сделать одномерный поиск с учетом условий Вольфе и исследовать эффективность.
5. Проанализируйте траекторию градиентного спуска для нескольких квадратич-
ных функций: придумайте две-три квадратичные двумерные функции, на которых работа метода будет отличаться, нарисуйте графики с линиями уровня
функций и траекториями методов.
Попробуйте ответить на следующий вопрос: Как отличается поведение метода
в зависимости от числа обусловленности функции, выбора начальной точки и
стратегии выбора шага?
6. Исследуйте, как зависит число итераций, необходимое градиентному спуску для
   сходимости, от следующих двух параметров:
      * числа обусловленности *k <= 1* оптимизируемой функции
      * размерности пространства n оптимизируемых переменных.
6.   Для этого для заданных параметров *n* и *k* сгенерируйте случайным образом
   квадратичную задачу размера *n* с числом обусловленности *k* и запустите на ней
   градиентный спуск с некоторой фиксированной требуемой точностью. Замерьте
   число итераций *T(n, k)*, которое потребовалось сделать методу до сходимости
   (успешному выходу по критерию остановки).
